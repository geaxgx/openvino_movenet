# MoveNet Single Pose tracking on OpenVINO

Running Google MoveNet Single Pose models on OpenVINO.

A convolutional neural network model that runs on RGB images and predicts [human joint
locations](https://github.com/tensorflow/tfjs-models/tree/master/pose-detection#coco-keypoints-used-in-movenet-and-posenet) of a single person. Two variant: Lightning and Thunder, the latter being slower but more accurate.
MoveNet uses an smart cropping based on detections from the previous frame when the input is a sequence of frames. This allows the model to devote its attention and resources to the main subject, resulting in much better prediction quality without sacrificing the speed.

![Demo](img/dance.gif)

For Blazepose, a challenger, please visit : [openvino_blazepose](https://github.com/geaxgx/openvino_blazepose)



## Install

You need OpenVINO 2021.3 (does not work with 2021.2) and OpenCV installed on your computer and to clone/download this repository.

## Run

**Usage:**

```
> python3 MovenetOpenvino.py -h                                               
usage: MovenetOpenvino.py [-h] [-i INPUT] [-p {16,32}]
                          [-m {lightning,thunder}] [--xml XML] [-d DEVICE]
                          [-s SCORE_THRESHOLD] [-o OUTPUT]

optional arguments:
  -h, --help            show this help message and exit
  -i INPUT, --input INPUT
                        Path to video or image file to use as input
                        (default=0)
  -p {16,32}, --precision {16,32}
                        Precision (default=32
  -m {lightning,thunder}, --model {lightning,thunder}
                        Model to use (default=thunder
  --xml XML             Path to an .xml file for model
  -d DEVICE, --device DEVICE
                        Target device to run the model (default=CPU)
  -s SCORE_THRESHOLD, --score_threshold SCORE_THRESHOLD
                        Confidence score to determine whether a keypoint
                        prediction is reliable (default=0.200000)
  -o OUTPUT, --output OUTPUT
                        Path to output video file
```
**Examples :**

- To use default webcam camera as input, Thunder model on CPU :

    ```python3 MovenetOpenvino.py```

- To use default webcam camera as input, Thunder model on MyriadX :

    ```python3 MovenetOpenvino.py -d MYRIAD```

- To use a file (video or image) as input :

    ```python3 MovenetOpenvino.py -i filename```

- To use Lightning instead of Thunder the version of the landmark model. 

    ```python3 BlazeposeOpenvino.py -m lightning```


|Keypress|Function|
|-|-|
|*space*|Pause
|c|Show/hide cropping region|
|f|Show/hide FPS|
|

## Performance with OpenVINO
My FPS measurements on a 30 seconds video:

||CPU (i7700k)|MyriadX|
|-|-|-|
|MoveNet Thunder|62|11.2|
|MoveNet Lightning|114|20.1|
|BlazePose Full|114|12.0|
|BlazePose Lite|132|19.9|
|


## The models 
They were generated by PINTO and are also available there: https://github.com/PINTO0309/PINTO_model_zoo/tree/main/115_MoveNet


## Credits
* [Google Next-Generation Pose Detection with MoveNet and TensorFlow.js](https://blog.tensorflow.org/2021/05/next-generation-pose-detection-with-movenet-and-tensorflowjs.html)
* Katsuya Hyodo a.k.a [Pinto](https://github.com/PINTO0309), the Wizard of Model Conversion !
